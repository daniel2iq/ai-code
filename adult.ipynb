{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e8080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: seaborn in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: category_encoders in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from category_encoders) (2.3.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from category_encoders) (2.3.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from category_encoders) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.6.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from category_encoders) (1.7.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from category_encoders) (1.16.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from category_encoders) (0.14.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\danie\\downloads\\target encoding ( data leakage)\\.venv\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
      "hello world\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_22392\\3603079639.py:35: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  x=x[filterd_df]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [0, 32561]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     66\u001b[39m final_pipeline =Pipeline([\n\u001b[32m     67\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m,preprocessor),\n\u001b[32m     68\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mfeature_selection\u001b[39m\u001b[33m\"\u001b[39m,SelectKBest(score_func=mutual_info_classif , k = \u001b[32m10\u001b[39m)),\n\u001b[32m     69\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mpolynomial features\u001b[39m\u001b[33m\"\u001b[39m,PolynomialFeatures(degree=\u001b[32m2\u001b[39m,include_bias=\u001b[38;5;28;01mFalse\u001b[39;00m,interaction_only=\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[32m     70\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m,LogisticRegression())\n\u001b[32m     71\u001b[39m ])\n\u001b[32m     75\u001b[39m kf = KFold(n_splits=\u001b[32m5\u001b[39m,shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m scores=\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthe  non skewed columns are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnon_skewed_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mcross validation scores :\u001b[39m\u001b[38;5;132;01m{scores}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\target encoding ( data leakage)\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\target encoding ( data leakage)\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\target encoding ( data leakage)\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\target encoding ( data leakage)\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:344\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[32m    142\u001b[39m \n\u001b[32m    143\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    340\u001b[39m \u001b[33;03m[0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    342\u001b[39m _check_groups_routing_disabled(groups)\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m X, y = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m params = {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n\u001b[32m    346\u001b[39m cv = check_cv(cv, y, classifier=is_classifier(estimator))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\target encoding ( data leakage)\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:530\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    501\u001b[39m \n\u001b[32m    502\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    529\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\target encoding ( data leakage)\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [0, 32561]"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas  matplotlib seaborn\n",
    "%pip install scikit-learn\n",
    "!pip install category_encoders\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"adult.csv\")\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,OrdinalEncoder , OneHotEncoder,PolynomialFeatures, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer \n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from scipy.stats import zscore\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "#from sklearn.feature_selection import SelectKBest,Mutual_info_classif \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "## those are the dependices \n",
    "\n",
    "\n",
    "print(\"hello world\")\n",
    "df.head()## prinitng the first few rows of the data set to see what were working witj\n",
    "df.isnull().sum()## also finidng the amount of missing values in the data so we can use simple imputer or other data imputation techniques \n",
    "\n",
    "\n",
    "x=df.drop(\"income\",axis=1)## we set the x axis to  every column but income\n",
    "y=df[\"income\"]## we set the y axis to target income\n",
    "numerical_cols=x.select_dtypes(include=[\"int64\",\"float64\"]).columns## we set numerical columns to every column that has numerical values and then get their names\n",
    "categorical_cols=x.select_dtypes(include=\"object\").columns## we do the samne here but for categorical columns \n",
    "z_scores = np.abs(zscore(x[numerical_cols])) ## we then set z score to be the absoutely value of each z score of every numerical_cols so we can effectively identify outliers \n",
    "filterd_df=df[z_scores<3].all(axis=1)## and then we look for every row that has a  standard devation less than 3\n",
    "x=x[filterd_df]## and then we set this new data frame as x\n",
    "\n",
    "skewed=  np.abs(x[numerical_cols].skew())## we then find the skew of each column in the numerical_columns , this is to find if its left or right skewed \n",
    "skewed_cols = [col for col in numerical_cols if skewed[col] >0.5]## we then check if the skew  is bigger than 0.5 , in which case that means it needs to be transformed \n",
    "non_skewed_cols=[col for col in numerical_cols if col not in skewed_cols]## and likewise we make a comprehnsion just incase it is not \n",
    "unique_cols = x[categorical_cols].nunique()## we then find out the amount of unique values in each categorical column\n",
    "small_unique=[col for col in categorical_cols if unique_cols[col]<10]## we sort out the  columns with large uniquye values by seeing if the unique values are less than 10\n",
    "big_unique=[col for col in categorical_cols if unique_cols[col]>10]## if the unique valuesa are not less than ten then we classify it as a big unique column\n",
    "\n",
    "skewed_cols_pipeline=Pipeline([## we make a pipeline to transform the skwed columsns , first power transforming it to reduce the skeweness level and then applying standardscaler to make the mean 1 and std =0\n",
    "    (\"power\",PowerTransformer(method=\"yeo-johnson\")),\n",
    "    (\"scale\",StandardScaler())\n",
    "])\n",
    "non_skewed_cols_pipeline=Pipeline([## we simply just scale the non skewed columns\n",
    "    (\"scale\",StandardScaler())\n",
    "])\n",
    "\n",
    "small_unique_cols_pipeline=Pipeline([## we use one hot encoder on the small unique pieplines , not much risk of creating thousands of  new columns\n",
    "    (\"onehot\",OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "\n",
    "big_unique_cols_pipeline = Pipeline([## we use target encoder for the big unique and high caridniltity pipeline , due to the fact it works for massive unique columns much better than most encoding types\n",
    "    (\"target\",TargetEncoder())\n",
    "])\n",
    "preprocessor = ColumnTransformer([## we use column transformer here to nae\n",
    "    (\"skewed\",skewed_cols_pipeline , skewed_cols),\n",
    "    (\"non_skewed_cols\",non_skewed_cols_pipeline,non_skewed_cols),\n",
    "    (\"small_unique\",small_unique_cols_pipeline,small_unique),\n",
    "    (\"big_unique\",big_unique_cols_pipeline,big_unique)\n",
    "])\n",
    "final_pipeline =Pipeline([\n",
    "    (\"preprocessor\",preprocessor),\n",
    "    (\"feature_selection\",SelectKBest(score_func=mutual_info_classif , k = 10)),\n",
    "    (\"polynomial features\",PolynomialFeatures(degree=2,include_bias=False,interaction_only=True)),\n",
    "    (\"model\",LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=42)## this is done so that to avioid data snooping bias and  data leakage\n",
    "scores=cross_val_score(final_pipeline,x,y,cv=kf)## this splits the data into 5 folds and each fold gets a chance to be the testing data while the other 4 are the training fold\n",
    "print(f\"the  non skewed columns are {non_skewed_cols}\")\n",
    "print(\"cross validation scores :{scores}\")## this is simply finding the scores of each fold\n",
    "print(f\" the mean scores are {scores.mean()}\")## and this is finding the mean , the closer to one the better \n",
    "\n",
    "print(f\" the skewed_cols are {skewed_cols}\")\n",
    "\n",
    "\n",
    "print (\"addional techniques i can use are \")\n",
    "print (\"-\"*40)\n",
    "##.count vectoriser and tdif vectoriser  for things like comments and unique words\n",
    "##.bayesian smooth encoding to prevent data leakage \n",
    "##.custom transformers to fit into pipelines seamlessly\n",
    "##feature crossing\n",
    "##.dimensionality reduction with e.g techniques like pca \n",
    "##. simple immputer to fill in missing values and also knn imputer and iteratve imputer \n",
    "##BIG NOTE - i did not use any of these techniques due to the fact that it wasnt needed on a data set like this\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a535c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
